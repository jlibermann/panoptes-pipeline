{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from piaa.utils import pipeline\n",
    "from piaa.utils import helpers\n",
    "\n",
    "from pocs.utils.images import fits as fits_utils\n",
    "\n",
    "from astropy.stats import sigma_clip, sigma_clipped_stats\n",
    "from astropy import units as u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation sources\n",
    "\n",
    "We use the previously detected and filtered sources to examine our target. See the [Source-Detection](Source-Detection-And-Filtering.ipynb) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/var/panoptes/images/fields/PAN012/358d0f/20180822T035809/'\n",
    "# base_dir = '/var/panoptes/images/fields/PAN001/Hd189733/14d3bd/20180913T085704/'\n",
    "source_filename = os.path.join(base_dir, f'point-sources-filtered.csv')\n",
    "\n",
    "sources = pipeline.lookup_sources_for_observation(filename=source_filename).set_index(['picid'], append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our target table we want to compare the flux as calculated from `sextractor` (which has no knowledge of the RGB array) with that pulled from a custom stamp.  `sextractor` uses a 6-pixel circular aperture  centered around the calculated centroid (the `x` and `y` values in our `sources` table) while our custom stamps will use an aperture that is sliced according to our rule of having a fixed pixel pattern. Here we use a 6-pixel aperture on our stamps for direct comparison with `sextractor` but the size can be vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_bias = 2048 * u.adu\n",
    "\n",
    "readout_noise = 10.5 * u.electron / u.pixel\n",
    "gain = 1.5 * (u.electron / u.adu)\n",
    "\n",
    "stamp_size = 10 * u.pixel\n",
    "num_pixels = (stamp_size**2).value\n",
    "\n",
    "# Lookup exposure time used\n",
    "exptime = fits_utils.getval(os.path.join(base_dir, sources.iloc[0].file), 'EXPTIME')\n",
    "\n",
    "num_sources = len(sources.index.levels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d29346b6c64fe78de7f93654484654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=847), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wtylergee/miniconda3/envs/pipeline/lib/python3.6/site-packages/ipykernel_launcher.py:54: RuntimeWarning: invalid value encountered in sqrt\n",
      "/home/wtylergee/miniconda3/envs/pipeline/lib/python3.6/site-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "counts = list()\n",
    "\n",
    "for pid, target_table in tqdm(sources.groupby('picid'), total=num_sources): \n",
    "    # Get PSC info for this target\n",
    "    psc = pd.read_csv(os.path.join(base_dir, 'stamps', f'{pid}.csv'), parse_dates=True).set_index(['obs_time', 'picid'])\n",
    "    \n",
    "    # Loop through each frame of the PSC\n",
    "    for idx, row in psc.iterrows():\n",
    "        date_obs= idx[0]\n",
    "        row_info = dict(date_obs=date_obs, picid=pid)\n",
    "        \n",
    "        # Get the counts with bias removed\n",
    "        stamp_counts = row.values - camera_bias.value\n",
    "        stamp_electrons = stamp_counts * gain.value\n",
    "        \n",
    "        back_mean, back_median, back_std = sigma_clipped_stats(stamp_electrons)\n",
    "        back_mean_counts = back_mean / gain.value\n",
    "        back_std_counts = back_std / gain.value\n",
    "        \n",
    "        # Store the overall flux\n",
    "        count_sum = (stamp_counts - back_mean_counts).sum()\n",
    "        count_noise = np.sqrt(count_sum)\n",
    "        \n",
    "        # Readout noise\n",
    "        readout = ((readout_noise) * num_pixels).value\n",
    "        readout = readout / gain.value    \n",
    "        \n",
    "        # Dark noise (see Zhang et al 2016)\n",
    "        dark_noise = (0.1 * exptime * num_pixels) / gain.value   \n",
    "        \n",
    "        counts.append({\n",
    "            'date_obs': date_obs,\n",
    "            'picid': pid,            \n",
    "            'channel': 'all',\n",
    "            'counts': count_sum,\n",
    "            'counts_noise': count_noise,\n",
    "            'back': back_mean_counts,\n",
    "            'back_noise': back_std_counts,\n",
    "            'readout_noise': readout,\n",
    "            'dark_noise': dark_noise,\n",
    "        })\n",
    "        \n",
    "        color_data = helpers.get_rgb_data(stamp_electrons.reshape(int(stamp_size.value), int(stamp_size.value)), force_new=True)\n",
    "\n",
    "        # Calculate some properties for each channel\n",
    "        for color, color_electrons in zip('rgb', color_data):\n",
    "            \n",
    "            back_mean, back_median, back_std = sigma_clipped_stats(color_electrons)\n",
    "            back_mean_counts = back_mean / gain.value\n",
    "            back_std_counts = back_std / gain.value\n",
    "            \n",
    "            color_counts = color_electrons / gain.value\n",
    "            count_sum = (color_counts - back_mean_counts).sum()\n",
    "            count_noise = np.sqrt(count_sum)\n",
    "            \n",
    "            if count_sum <= 0:\n",
    "#                 print(f'Negative stamp: {pid} {color} {date_obs} {stamp_sum}')\n",
    "                continue\n",
    "                \n",
    "            n_stamp_pixels = int(color_electrons.count())\n",
    "                        \n",
    "            # Readout noise\n",
    "            readout = ((readout_noise) * n_stamp_pixels).value\n",
    "            readout = readout / gain.value    \n",
    "\n",
    "            # Dark noise (see Zhang et al 2016)\n",
    "            dark_noise = (0.1 * exptime * n_stamp_pixels) / gain.value\n",
    "\n",
    "            counts.append({\n",
    "                'date_obs': date_obs,\n",
    "                'picid': pid,\n",
    "                'channel': color,\n",
    "                'counts': count_sum,\n",
    "                'counts_noise': count_noise,\n",
    "                'back': back_mean_counts,\n",
    "                'back_noise': back_std_counts,\n",
    "                'readout_noise': readout,\n",
    "                'dark_noise': dark_noise,\n",
    "            })            \n",
    "\n",
    "source_noise = pd.DataFrame(counts).set_index(['date_obs'])\n",
    "source_noise.index = pd.to_datetime(source_noise.index)\n",
    "source_noise.to_csv(os.path.join(base_dir, f'point-sources-noise.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
